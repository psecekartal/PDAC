---
title: "Prepare 16S data"
author: "Sebastian Schmidt"
date: "2019-06-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(stringsAsFactors = FALSE)
```

## Prepare Environment

Attach relevant packages

```{r, echo = F}
source("https://raw.githubusercontent.com/defleury/Toolbox_16S/master/R/function.alpha_diversity.R")
source("https://raw.githubusercontent.com/defleury/Toolbox_16S/master/R/function.rarefaction.R")
source("https://raw.githubusercontent.com/defleury/Schmidt_et_al_2016_community_similarity/master/functions.community_similarity.R")

library("Matrix", warn.conflicts=F, quietly=T)
library("ggplot2", warn.conflicts=F, quietly=T)
library("RColorBrewer", warn.conflicts=F, quietly=T)
library("tidyverse", warn.conflicts=F, quietly=T)
```

Set parameters.

```{r}
PARAM <- list()
PARAM$folder.R <- paste0(getwd(), "/")
PARAM$folder.base <- gsub("Rmd/", "", PARAM$folder.R)
PARAM$folder.data <- paste0(PARAM$folder.base, "data/")
PARAM$folder.metadata <- paste0(PARAM$folder.base, "metadata/")
PARAM$folder.parameters <- paste0(PARAM$folder.base, "parameters/")
PARAM$folder.results <- paste0(PARAM$folder.base, "results/")

#Set parameters to filter taxa tables
PARAM$min.size_sample <- 500
PARAM$min.prevalence_tax <- 5
PARAM$use.cores <- 4
```

## Load and Consolidate Metadata

Metadata is available in two separate tables. Load these and consolidate the info.

Load sample and experiment data from saliva and stool runs.

```{r, echo=F}
#Sample metadata
data.sample.ST_OR.raw <- read.table(file=paste0(PARAM$folder.metadata, "ES_PC_Pancreatic_cancer.tsv"), sep="\t", comment="#", header=T)

#Experiment metadata
read.table(file=paste0(PARAM$folder.metadata, "ES_PC_experiment_PC_2018.tsv"), sep="\t", comment="#", header=T) %>% filter(library_strategy == "AMPLICON") -> data.exp.ST_OR.raw
```

Load data for tissue and serum run.

```{r, echo=F}
#Sample metadata
data.sample.SE_TI.raw <- as.data.frame(read_delim(paste0(PARAM$folder.metadata, "ES_PC_sample_tissue_serum.tsv"), "\t", escape_double = FALSE, comment = "#", trim_ws = TRUE))

#Experiment metadata
read.table(file=paste0(PARAM$folder.metadata, "ES_PC_experiment_tissue_serum.tsv"), sep="\t", comment="#", header=T) %>% filter(library_strategy == "AMPLICON") -> data.exp.SE_TI.raw
```

Select variables of interest and merge tables.

```{r}
#Merge data.sample.raw
keep.variables.sample <- c(
  "sample_alias", "subject_id",
  "environment_material",
  "center", "age_years", "gender", "smoker", "alcohol_status", "alldiab", "diabcat", "diabmed", "metformin.ever", "periodontitis",
  "artificial",
  "subject_disease_status", "intervention",
  "aliases"
)
data.sample.raw <- rbind(data.sample.ST_OR.raw[, keep.variables.sample], data.sample.SE_TI.raw[, keep.variables.sample])

#Merge data.exp.raw
data.exp.ST_OR.raw$extraction <- NA
keep.variables.exp <- c("experiment_name", "sample_alias", "read_count", "aliases", "extraction")
data.exp.raw <- rbind(data.exp.ST_OR.raw[, keep.variables.exp], data.exp.SE_TI.raw[, keep.variables.exp])

#Cross-filter and merge tables
data.sample.merged <- left_join(data.exp.raw, data.sample.raw, by="sample_alias")
```

## Load Raw Taxa Tables

Read ASV table.

```{r}
file.asv_table <- paste0(PARAM$folder.data, "all_samples.asv_table.tsv.gz")
tmp.asv <- as.matrix(read.delim(file.asv_table, sep="\t", header=T, row.names = 1))
dim(tmp.asv)
```

Filter by sample sizes and minimum taxa prevalence.

```{r}
t.asv <- tmp.asv[rowSums(tmp.asv > 0) >= PARAM$min.prevalence_tax, colSums(tmp.asv) >= PARAM$min.size_sample]
dim(t.asv)
```

After applying these filters, we retain `r round(100 * ncol(t.asv) / ncol(tmp.asv), digits=2)`% of samples, `r round(100 * nrow(t.asv) / nrow(tmp.asv), digits=2)`% of ASVs and `r round(100 * sum(t.asv)/sum(tmp.asv), digits=2)`% of total reads. Indeed, the removed samples contained just `r round(100 * sum(tmp.asv[, colSums(tmp.asv) < PARAM$min.size_sample]) / sum(tmp.asv), digits=2)`% of total reads.

Get sample sizes, re-scale (by removing samples that retain <80% of the previously set minimum size) and normalise by total sums.

```{r}
#tmp.size <- colSums(t.asv)
#t.asv <- t.asv[, tmp.size >= 0.8*PARAM$min.size_sample]
size.asv <- colSums(t.asv)
t.asv.rel <- t(t(t.asv) / size.asv)
dim(t.asv)
```

Parse mapping of ASVs to specI clusters from `MAPseq` output file.

```{r}
tmp.ms <- read.table(paste0(PARAM$folder.data, "all_samples.asv.ms.gz"), row.names = 1)

#Match to previously filtered ASVs
data.map.asv_specI <- tmp.ms[rownames(t.asv), c(3:5, 12, 14)]
colnames(data.map.asv_specI) <- c("seq_id", "alignment_length", "mismatches", "specI", "conf")
rownames(data.map.asv_specI) <- rownames(t.asv)

#Filter by minimum seq identity and mapping confidence
data.map.asv_specI[!is.na(data.map.asv_specI$seq_id) & (data.map.asv_specI$seq_id < 0.98 | data.map.asv_specI$conf < 0.25), "specI"] <- NA
```

Load raw ASV taxonomy data.

```{r}
tmp.asv <- read.delim(paste0(PARAM$folder.data, "all_samples.asv_data.tsv.gz"), header = T, row.names = 1)
data.taxonomy.asv <- cbind(tmp.asv[rownames(t.asv), ], data.map.asv_specI)
```

Repeat for open-reference 98% OTU table.

```{r}
file.otu_table <- paste0(PARAM$folder.data, "all_samples.open_ref.otu_table.tsv.gz")
tmp.otu <- as.matrix(read.delim(file.otu_table, sep="\t", header=T, row.names = 1))
dim(tmp.otu)
```

```{r}
#First round of filtering.
t.otu <- tmp.otu[rowSums(tmp.otu > 0) >= PARAM$min.prevalence_tax, colSums(tmp.otu) >= PARAM$min.size_sample]
dim(t.otu)
```

```{r}
#Second round of filtering
tmp.size <- colSums(t.otu)
t.otu <- t.otu[, tmp.size >= 0.8*PARAM$min.size_sample]
size.otu <- rowSums(t.otu)
dim(t.otu)
```

After applying these filters, we retain `r round(100 * ncol(t.otu) / ncol(tmp.otu), digits=2)`% of samples, `r round(100 * nrow(t.otu) / nrow(tmp.otu), digits=2)`% of OTUs and `r round(100 * sum(t.otu)/sum(tmp.otu), digits=2)`% of total reads. Indeed, the removed samples contained just `r round(100 * sum(tmp.otu[, colSums(tmp.otu) < PARAM$min.size_sample]) / sum(tmp.otu), digits=2)`% of total reads.

Load and filter OTU data.

```{r}
file.otu_data <- paste0(PARAM$folder.data, "all_samples.open_ref.otu_data.tsv.gz")
tmp.otu <- read.delim(file.otu_data, sep="\t", header=T, row.names = 1)

data.taxonomy <- tmp.otu[rownames(t.otu), ]
data.taxonomy$size <- size.otu
```

## Adjust Sample Data

Subset to samples retained post filtering of the OTU table.

```{r}
data.sample.merged %>% filter(experiment_name %in% colnames(t.otu)) -> data.sample.tmp
```

Merge technical replicates in OTU and ASV tables.

```{r}
all.alias <- unique(data.sample.tmp$sample_alias)
data.otu <- matrix(0, nrow=nrow(t.otu), ncol=length(all.alias), dimnames = list(rownames(t.otu), all.alias))
data.asv <- matrix(0, nrow=nrow(t.asv), ncol=length(all.alias), dimnames = list(rownames(t.asv), all.alias))
data.sample <- data.frame()

for (s in all.alias) {
  #Process OTUs
  c.otu <- t.otu[, data.sample.tmp$experiment_name[data.sample.tmp$sample_alias == s]]
  if (is.null(ncol(c.otu))) {
    data.otu[, s] <- c.otu
    data.sample <- rbind(data.sample, data.sample.tmp[data.sample.tmp$sample_alias == s, ])
  } else {
    data.otu[, s] <- rowSums(c.otu)
    data.sample <- rbind(data.sample, data.sample.tmp[data.sample.tmp$sample_alias == s, ][1, ])
  }
  
  #Process ASVs
  c.asv <- t.asv[, data.sample.tmp$experiment_name[data.sample.tmp$sample_alias == s]]
  if (is.null(ncol(c.asv))) {
    data.asv[, s] <- c.asv
  } else {
    data.asv[, s] <- rowSums(c.asv)
  }
}
```

Rename rows and colums in `data.otu`, `data.asv` and `data.sample` to match.

```{r}
data.otu <- data.otu[, data.sample$sample_alias]
data.asv <- data.asv[, data.sample$sample_alias]

rownames(data.sample) <- colnames(data.otu) <- colnames(data.asv) <- data.sample$experiment_name
```

Get relative abundance tables.

```{r}
size.sample <- colSums(data.otu)
data.otu.rel <- t(t(data.otu) / size.sample)

data.asv.rel <- t(t(data.asv) / colSums(data.asv))
```

Track read stats.

```{r}
data.sample$size <- size.sample
reads.retained <- data.sample$size / data.sample$read_count
reads.retained.asv <- colSums(data.asv) / data.sample$read_count

hist(reads.retained, 50)
hist(reads.retained.asv, 50)
```

Define sample types (material).

```{r}
data.sample$material <- gsub(" \\[.+", "", data.sample$environment_material)
data.sample$material[grepl("TU", data.sample$experiment_name)] <- "pancreas_tumor"
data.sample$material[data.sample$material == "blood plasma"] <- "blood_plasma"
data.sample$material[!is.na(data.sample$artificial)] <- paste(data.sample$material[!is.na(data.sample$artificial)], data.sample$artificial[!is.na(data.sample$artificial)], sep=".")

data.sample$material <- factor(data.sample$material, levels = c(
  "saliva",
  "feces",
  "blood_plasma",
  "blood_plasma.negative_control",
  "duodenum",
  "duodenum.cultivation",
  "pancreas",
  "pancreas.cultivation",
  "pancreas.negative_control",
  "pancreas_tumor",
  "pancreas_tumor.cultivation"
))
```


## Calculate per-Sample Diversities

Calculate per-sample alpha diversity.

```{r}
#Calculate rarefied alpha diversities
alpha.frame <- Hill_Diversity.rarefied(data.otu, size=PARAM$min.size_sample, iterations=100, q.H=c(0, 1, 2))
rownames(alpha.frame) <- as.character(alpha.frame$sample.name)

#Append to sample data
data.sample <- cbind(data.sample, alpha.frame[rownames(data.sample), ])
```


Calculate between-sample compositional overlap (beta diversity).

```{r}
#Calculate sample dissimilarities
beta.div <- list();

#Bray-Curtis
beta.div[["Bray_Curtis"]] <- community.similarity.par(data.otu.rel, distance="bray_curtis", use.cores=PARAM$use.cores)

#Jaccard
beta.div[["Jaccard"]] <- community.similarity.par(data.otu.rel, distance="jaccard", use.cores=PARAM$use.cores)

#Weighted Jaccard
beta.div[["Jaccard_w"]] <- community.similarity.par(data.otu.rel, distance="jaccard.abd.frac", use.cores=PARAM$use.cores)

#Get pairwise (raw) SparCC correlations and derived "interaction matrix"
taxa.sparcc <- sparcc(data.otu.rel, size.thresh=0, pseudocount=10^-6, nblocks=4, use.cores=PARAM$use.cores)
taxa.sparcc.S <- 0.5 * (cor(taxa.sparcc) + 1)

#Unweighted TINA
beta.div[["TINA_uw"]] <- community.similarity.corr.par(data.otu.rel, S=taxa.sparcc.S, distance="jaccard.corr.uw.norm", blocksize=10, use.cores=PARAM$use.cores)
beta.div[["TINA_uw"]][beta.div[["TINA_uw"]] < 0] <- 0
rownames(beta.div[["TINA_uw"]]) <- colnames(beta.div[["TINA_uw"]]) <- colnames(data.otu.rel)

#Weighted TINA
beta.div[["TINA_w"]] <- community.similarity.corr.par(data.otu.rel, S=taxa.sparcc.S, distance="jaccard.corr.w.norm", blocksize=10, use.cores=PARAM$use.cores)
beta.div[["TINA_w"]][beta.div[["TINA_w"]] < 0] <- 0
rownames(beta.div[["TINA_w"]]) <- colnames(beta.div[["TINA_w"]]) <- colnames(data.otu.rel)

#Store in R format
save(beta.div, file=paste0(PARAM$folder.data, "16S.data.beta_div.RData"))
save(taxa.sparcc, file=paste0(PARAM$folder.data, "16S.data.sparcc.RData"))
```


Store sample and taxa data.

```{r}
save(data.sample, file=paste0(PARAM$folder.data, "16S.data.sample.RData"))
save(data.otu, data.otu.rel, data.taxonomy, file=paste0(PARAM$folder.data, "16S.data.otu.RData"))
save(data.asv, data.asv.rel, data.map.asv_specI, data.taxonomy.asv, file=paste0(PARAM$folder.data, "16S.data.asv.RData"))
```






